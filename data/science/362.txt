استخدام الذكاء الاصطناعي في التوظيف.. فضائح وقضايا أخلاقية 

 تعلمت البشرية من جائحة كورونا دروسا كثيرة، لعل من أبرزها المرونة في العمل وأهمية التكنولوجيا، لا سيما الذكاء الاصطناعي والتعلم الآلي في إدارة شؤون الحياة. ونجحت الشركات في استخدام هذه الأدوات بفعالية في عمليات التوظيف والتدريب وتقييم الأداء، كما ساعد الذكاء الاصطناعي الشركات على اتخاذ قرارات توظيف أفضل عبر الاستجابة بشكل أسرع. وتستخدم الشركات الخوارزميات من أجل تحليل البيانات حول آلاف المتقدمين للوظائف لديها واختيار الأفضل من بينهم، وباستخدام الذكاء الاصطناعي أصبحت الموارد البشرية تعمل بشكل أكثر كفاءة بكثير مما كانت عليه الحال في السابق. ومن المتوقع أن ينمو حجم سوق الذكاء الاصطناعي العالمي من 47.47 مليار دولار أميركي عام 2021 إلى 360.36 مليار دولار عام 2028، بمعدل نمو سنوي مركب يبلغ 33.6%، وهذا النمو سيعني مزيدا من الاعتماد على الذكاء الاصطناعي في كافة أقسام العمل، بما فيها قطاع التوظيف والتدريب، وذلك كما ذكر موقع "إيه بي إن نيوز" (apnnews) مؤخرا. وخلص استطلاع للرأي أُجري مؤخرا على خبراء ومختصي الموارد البشرية في اليابان إلى أن أكثر من 60% من المشاركين في الاستطلاع أجابوا بأن لديهم توقعات إيجابية حول استخدام الذكاء الاصطناعي في عمليات التوظيف، كما ذكرت منصة "تكنولوجي" (technology.org) أخيرا. وسيلعب الذكاء الاصطناعي دورا محوريا في عمليات التوظيف في المستقبل، وفي الحقيقة فقد بدأنا نشاهد هذا الدور منذ الآن، إذ تعتمد كثير من شركات التوظيف العالمية على استخدام الخوارزميات والذكاء الاصطناعي في اختيار الموظفين المناسبين. لكن هناك وجها آخر مظلما لهذه العملية، إذ يمكن أن يشكل هذا الاستخدام معضلة أخلاقية وتهديدا حقيقيا لخصوصية المستخدمين، ولعل واحدا من أبرز الأمثلة على ذلك هو ما أصبح يعرف عالميا باسم "فضيحة بيانات ريكونابي اليابانية" (The Japanese Rikunabi Data Scandal)، وهي الفضيحة التي ناقشها الباحثون: فوميكو كودو، وهيرومي أراي، وأريسا إيما في ورقة تحت عنوان "القضايا الأخلاقية المتعلقة باستخدام الذكاء الاصطناعي في عمليات التوظيف.. فضيحة ريكونابي نموذجا". في كل عام يتخرج نحو 800 ألف طالب من المعاهد والجامعات اليابانية، ويدخلون سوق العمل بحثا عن الوظيفة المناسبة لمؤهلاتهم، وهناك أكثر من 31 ألف شركة يابانية تتطلع لتوظيف هؤلاء الخريجين أو اختيار المناسب منهم لعملياتها، وجميع هؤلاء (الطلاب والشركات) مسجلون في واحد من أكبر مواقع التوظيف عبر الإنترنت في اليابان، وهو موقع "ريكونابي" وهو تابع لشركة "ريكروت كارير"، التي تقدم خدماتها للخريجين الجدد. حيث تقوم الشركة بدور الوسيط بين الخريجين الباحثين عن عمل والشركات التي تبحث عن المرشحين المناسبين للشواغر الوظيفية التي تملكها. وفي أثناء هذه العملية تقوم الشركة بجمع وتحليل المعلومات الديموغرافية وملفات تعريف الارتباط للباحثين عن عمل (الطلاب) التي تم جمعها من خلال خدمة المطابقة مع حاجات الشركات، وتحسب كذلك درجة احتمالية مناسبة كل خريج مع حاجات الشركات، وذلك من خلال استخدام خوارزميات تحليل خاصة بها. الفضيحة بدأت عندما تسربت معلومات إلى وسائل الإعلام اليابانية بأن الشركة باعت بيانات الطلاب الباحثين عن عمل إلى ما لا يقل عن 38 شركة يابانية؛ من بينها شركات مشهورة مثل تويوتا وميتسوبيشي، وهو الأمر الذي أثار ضجة كبرى في اليابان، وأدى إلى قيام مكتب العمل في طوكيو بالتحقيق في الحادثة. وتوصل التحقيق إلى أن مشاركة شركة "ريكروت كارير" المعلومات الشخصية مع الشركات العميلة تنتهك قانون ضمان العمل، وهو ما نتج عنه فرض غرامات باهظة على الشركة. وعودة إلى الورقة البحثية المذكورة آنفا، فقد ناقشت باستفاضة المخاوف الأخلاقية المتعلقة باستخدام الخوارزميات والذكاء الاصطناعي، أو ما تعرف بتكنولوجيا الموارد البشرية في عمليات التوظيف، وكم المعلومات والبيانات الهائل التي يتم جمعها، سواء عن طالبي التوظيف أو الشركات التي تبحث عن المواهب الضرورية لاستمرار عملها. وخلصت الورقة إلى استنتاجات مهمة؛ لعل أبرزها أن "درجة احتمالية قبول أو رفض الطلاب عروض العمل تعتمد على المعلومات الشخصية، وقد لا تكون المعلومات الشخصية نفسها هي الأهم، ولكن طرق التعامل معها وأساليب تحليلها، ومن الممكن أن يؤدي الإفراط في الاعتماد على التكنولوجيا إلى خلق إشكاليات أخلاقية واجتماعية، وهو الأمر الذي قد يمثل تحديات أمام المطورين أو الشركات لقبولها، وكلما زادت دقة التحليل زادت احتمالية قبول النتائج على أنها حقائق مسلم بها، مما يؤدي إلى زيادة مخاطر انتهاك المصالح القانونية والاجتماعية بشأن موضوع البيانات". كما أوضح الباحثون أنه "لا توجد تعليمات وإرشادات قانونية محددة قادرة على أن تحقق التوازن بين دقة التحليل وحماية البيانات الشخصية، وبالتالي تصبح المناقشة الأخلاقية والاجتماعية في غاية الأهمية". وأكد الباحثون أنه "من أجل بناء توافق في الآراء بين مختلف الجهات الداخلة في عملية التوظيف، فقد أصبح من المهم للغاية وضع تعليمات وإرشادات قانونية واضحة تنظم عمل التكنولوجيا في قطاع الموارد البشرية، ويجب أن تتماشى هذه الإرشادات والتعليمات مع مبادئ حوكمة الذكاء الاصطناعي العالمية، بالإضافة إلى السياق الوطني وعادات وتقاليد المجتمع". ورغم وقوع هذا الحادث في اليابان فقد أنهى الباحثون ورقتهم بالأمل في أن "تسهم هذه القضية والنقاش الذي دار حولها في بناء نظام أخلاقي واضح في التعامل مع الذكاء الاصطناعي، لا سيما في طريقة التعامل مع البيانات الشخصية الحساسة". وفي الختام، يبقى القول إن من قام ببيع تلك البيانات هم بشر وليس الذكاء الاصطناعي في حد ذاته، وتبقى المسألة كما هي منذ الأزل: كيف نتعامل نحن البشر مع معطيات الثورة الصناعية الرابعة؟ وهو سؤال سيبقى دائما ينتظر الإجابة.